<!DOCTYPE html>
<html>
<head>
        <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
        <link rel="stylesheet" type="text/css" href="styles.css" />
	<link rel="stylesheet" href="prism.css">
	<script src="prism.js"></script>

        <h1>Ky McCormick - Personal Site</h1>

        <nav>
                <a href="./index.html">[resume]</a>
                <a href="./projects.html">[projects]</a>
                <a href="./aboutme.html">[about me]</a>
                <a href="./today.html">[todays info]</a>
        </nav>
        <hr>
</head>
<body>
	<title>Ky McCormick Personal Site</title>
	<hr>
	<h2>Key Identification Using Machine Learning</h2>
	<p>Since I started at Drexel, I have been interested in the overlap between music and computer science. At first 
	   I was interested in using AI generation, but I have since soured on that, then I was looking at the mathematical 
	   sides behind music and then it hit me. Lately, when playing bass and looking at the keys given for a specific 
	   song by sites like https://tunebat.com/ and https://tabs.ultimate-guitar.com/ I kept seeing that the keys given 
	   do not line up with what I hear or that the keys given are not consistent across versions. With that in mind </p>
	<hr>   
	<p> I started looking at key identification using Machine Learning and wanted to see if there was anyone who've
	    done similar. Sadly, there's not much out there on anything lower than a very high academic level. Spotify 
	    likes to keep it's secrets ... here are the papers</p>
	<ul>
		<li>1. <a href="http://davidtemperley.com/wp-content/uploads/2015/11/temperley-mp99.pdf">Krumhansl-Schmuckler Algo</a></li>
		<li>2. <a href="https://cs229.stanford.edu/proj2016/report/Mahieu-DetectingMusicalKeyWithSupervisedLearning-report.pdf">Detecting Musical Key with Supervised Learning</a></li>
		<li>3. <a href="https://link.springer.com/article/10.1007/s11042-022-12432-y">Development of an intelligent model for musical key estimation using machine learning techniques</a></li>
	</ul>

	<p>Great, but what the hell do these papers mean? What use are they to me, or to anyone? what can we pull
	   out from them, that vein of gold burried deep, that kernel around which we can build and build and buld like
	   the speck of dust at a center of a raindrop? To the best of my ability, it can but sumarised as follows:</p>
	<ul>
		<li>1. Music, like all sounds, is quantifiable as a series of waves. We use hertz for this measure </li>
		<li>2. Sadly, due to overtones and interference, hitting one note does not trigger just one note and noise is a big issue </li>
		<li>3. We can use short time fourier transforms and a whole lot of frequency filtering to clean up the noise as best as possible and match the note to its expected frequency AND velocity</li>
		<li>4. We then can cut this into sections (say 30s-1m) and then average the velocity and occurance of each note over said time to get an average chroma-vector</li>
		<li>5. The chroma-vector forms the basis for all of the machine learning algorithms. It (and the key) are the inputs </li>
	</ul>
	<hr>
	<p>Ok cool. So now it's a day later. I spent too much time and (finally) have a working database that promises to be varied enough
	   and wont 1. cost me monies or 2. require me to like do individual dowloads or map the keys myself. It's important to have a 
	   verified basis of truth. Bad part. It's all in .abc files. .abc is a very old file type from the 1990s and 2000s used to write
	   music in ASCII. It was mostly used for traditional folk songs. Luckily, (after WAY too many broken links) I found a converter
	   in c to do this for me, but hey. I know c, I know python. I'll be back after I make a converter.
	</p>
	<br>
	<br>
	<p>I'm back. It's been about two hours. Here's the script! It's a remarkably simple thing, most of the time was spent actually
	   doing the test conversions.
	</p>
	<pre><code class="language-python">
	  import sys, re
	  from subprocess import call

	  def main():
	    abc_file = sys.argv[1]
	    abc_file = open(abc_file, "r").read().split("\n\n")

	    for i in range(len(abc_file)):
	      if(len(abc_file[i]) > 2):
	        f = open("test.abc", "w")
		f.write(abc_file[i])
		f.close()
		song_name = re.findall("T:(.*)", abc_file[i])[0].replace(" ", "_").replace("'","")
		song_key = re.findall("\nK:(.*)", abc_file[i])[0]
		filename = "midi_files/" + song_name + '+Key_' + song_key

		call(["./abc2midi.exe", "test.abc", "-o", filename])
	  
	  main()
	</code></pre>
	<br>
	<p>Cool. Let's run some transformations and see the results.<p>
	<hr>
	<p>It's the next day now. Some bad news everyone! The database was seemingly not as varried as implied. I was looking through the
	   files and did some basic just like checkwork and the amount of each key seemed a little off. Some keys seems to be very heavily
	   represented, so I did more investigation using grep and wc and found out bad news! Nearly half the possible keys are not
	   in the dataset! How dare the internet lie to me! This is annoying ugghghh. Now what.
	<br>
	   So. New plan. Let's look at the top 15 songs in each non-theoretical key (for non music nerds, that means keys that are 
	   realistically played).Get mp3s for each, then slice them into 30 second blocks and remove percussive features, normalise, 
	   and filter, then use. Now for how I am gonna get these as mp3s (or oog, or flac, or wav)...
	</p>
	<hr>
	<p>Finally, three days later, I've got enough data. It was VERY tedious and annoying to try to find mp3s. Let's not ask questions
	   but I have all the data needed. I processed this data as follows: I first labeled the file with a separator and key information
	   then I created a function called processMp3Data(dir) which takes the mp3 file directory and creates a matrix representation
	   with each row representing a thirty second snipit of an audio file with the last feature as the labeled key, and the rest as the
	   average chroma-vector over that period. The code for this function and explanation is below.
	</p>
	<ul>
		<li>1. Create a dummy matrix to start then begin a loop for every file in the mp3 directory</li>
		<li>2. Find the key from the song title using regex, filter out noise and percussion, and create the chromagraph</li>
		<li>3. For each 30s song chunk, grab that slice from the chromagraph matrix, then calculate the average chromavector</li>
		<li>4. Add the key to this chromavector to create the feature vector and stack it onto the dummy matrix</li>
	</ul>
	<pre><code class="language-python">
     def processMp3Data(dir):
	feature_matrix = np.zeros((0,13))

    	  for file in os.listdir(dir):
          f = os.path.join(dir, file)

          if os.path.isfile(f):
            print(f)
            # get length of song in seconds, then number of 30 second snippets to make
            length = librosa.get_duration(path=f)
            itters = int(length // 30) 

            # get the key from title
            key = re.findall('\+Key\_(.*)\.',f)[0]

            # load the song, filter out local noise and percussion
            y, sr = librosa.load(f)
            y_harm = librosa.effects.harmonic(y=y, margin=8)
            chroma_harm = librosa.feature.chroma_stft(y=y_harm, sr=sr)
            chroma_filter = np.minimum(chroma_harm,
                           librosa.decompose.nn_filter(chroma_harm,
                                                       aggregate=np.median,
                                                       metric='cosine'))

            # for each 30 second chunk of the song, create an entry
            for i in range(itters):

                if (i+1) * 30 &lt= length:
                    x = (i+1) * 30
                    idx = tuple([slice(None), slice(*list(librosa.time_to_frames([i*30, (i+1)*30])))])
                else:
                    idx = tuple([slice(None), slice(*list(librosa.time_to_frames([i*30, length])))])

                feature_vector = np.mean(chroma_filter[idx],axis=1)
                feature_vector = np.append(feature_vector, key)
                
                feature_matrix = np.vstack((feature_matrix, feature_vector))

    	return feature_matrix
	</code></pre>
	<br>
	<hr>
	<br>
	<p>Now  that we have the data in a digestable format, there's one small tweak and one large tweak left before we
	   can use it for machine learning. An old phrase a prof told me is Machine Learning is 20% statistics, 20% linear alg,
	   and 60% just getting the data to where you need it. Anyways... 
	   <br><br>
	   The simple tweak is that instead of A, Ab, Abm, etc for keys
	   they need to be given as numbers, just for ease of processing en mass with numpy. I just threw the results of the above
	   function into a pandas dataframe and exported that as a csv, then used mass edits in my csv editor of choice.
	<br><br>
	   The more complicated one is that well 24 dimmensional data is not very easy to work with. Some machine learning algos behave
	   badly with high dimmensions, some just get much more computationally intense, and while I am doing this on a fairly beefy
	   PC and not a TON of data, 1392 datapoints with 24 features... it'll be for the best. Moreover, I am not sure yet on which
	   dimmension we will perform best, if any from reduction. If I was to use Krumhansl's algorithm, then of course reduction would
	   not be beneficial, but we are exploring the use of machine learning for key classification, so we need to apply machine learning
	   logic.
	<br><br>
	   To reduce the number of features per entry while preservince class separation, we must use Linear Discriminant Analysis.
	   Details of LDA can be found <a href="./lda">here</a>
	</p>

</body>
</html>
